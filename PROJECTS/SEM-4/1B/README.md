
# Realâ€‘Time Sign Language Detection System

*Semester 4 â€“ Gesture Recognition with Python, OpenCV & MediaPipe*

---

## ğŸ¯ Project Overview  
This project delivers a real-time sign language recognition system utilizing webcam input. MediaPipe is used for hand landmark detection, with custom gesture classification logic to map gestures to letters or words. Detected outputs are overlaid on the video stream.

---

## ğŸ§° Folder Structure

```
Sign_Language_Detection/
â”œâ”€â”€ main.py                          # Entry point to start real-time capture & detection
â”œâ”€â”€ gesture_classifier.py           # Logic to map landmarks to sign labels
â”œâ”€â”€ dataset/                         # Folder containing recorded gesture images or landmark dumps
â”‚   â””â”€â”€ [label]/
â”‚       â”œâ”€â”€ img1.jpg
â”‚       â”œâ”€â”€ img2.jpg
â”œâ”€â”€ utils.py                         # Utility scripts (e.g. preprocessing, threshold tuning)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup & How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/Shrenik027/my-projects.git
   ```
2. Navigate into the folder:
   ```bash
   cd my-projects/PROJECTS/Sign_Language_Detection
   ```
3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
4. Run the application:
   ```bash
   python main.py
   ```
5. Use your webcam to show hand signs; the system will detect each gesture and display the corresponding letter/word on-screen.

---

## ğŸ“Œ Core Features

- Live hand landmark tracking (21 key-points via MediaPipe)  
- Gesture classification logic: rule-based or simple model using landmark positions  
- Overlay detected sign output on live webcam feed  
- Adjustable parameters for sensitivity & confidence thresholds

---

## ğŸ‘¤ My Contributions

- Led dataset preparation: recorded gestures under varied lighting and angles  
- Developed real-time processing pipeline: webcam input â†’ landmark extraction â†’ classification  
- Tuned classification logic for accuracy and responsiveness  
- Managed integration and demo to peers/instructor

---

## ğŸ§  Skills Gained

- MediaPipe hand tracking & landmark extraction  
- Real-time OpenCV video stream integration  
- Mapping landmarks to recognized signs  
- UI overlay rendering and real-time feedback loops  
- Handling gesture variability across users

---

## ğŸ“… Timeline

Completed: September 2024 (Semester 4)

---

## ğŸ”® Future Enhancements

- Build a trained ML model (e.g., CNN classifier or random forest) for improved accuracy  
- Expand to a larger sign vocabulary including words and phrases  
- Deploy via Streamlit or a web/mobile interface for wider accessibility
